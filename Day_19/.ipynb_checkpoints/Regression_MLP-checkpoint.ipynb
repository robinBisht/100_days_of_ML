{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /home/robin/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full,X_test,y_train_full,y_test = train_test_split(housing.data,housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_full,y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_scaled = scaler.fit_transform(X_valid)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30,activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='sgd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9111 - val_loss: 0.6290\n",
      "Epoch 2/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4946 - val_loss: 0.4858\n",
      "Epoch 3/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4451\n",
      "Epoch 4/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4341\n",
      "Epoch 5/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4324\n",
      "Epoch 6/33\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3728 - val_loss: 0.4210\n",
      "Epoch 7/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4303\n",
      "Epoch 8/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.4215\n",
      "Epoch 9/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.4168\n",
      "Epoch 10/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.4129\n",
      "Epoch 11/33\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.4157\n",
      "Epoch 12/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.4199\n",
      "Epoch 13/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.4159\n",
      "Epoch 14/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.4016\n",
      "Epoch 15/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3996\n",
      "Epoch 16/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.4146\n",
      "Epoch 17/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.4308\n",
      "Epoch 18/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3927\n",
      "Epoch 19/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.4014\n",
      "Epoch 20/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3976\n",
      "Epoch 21/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3196 - val_loss: 0.3981\n",
      "Epoch 22/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3883\n",
      "Epoch 23/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3850\n",
      "Epoch 24/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3968\n",
      "Epoch 25/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.4202\n",
      "Epoch 26/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3111 - val_loss: 0.3929\n",
      "Epoch 27/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3880\n",
      "Epoch 28/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3120 - val_loss: 0.4138\n",
      "Epoch 29/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3877\n",
      "Epoch 30/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3970\n",
      "Epoch 31/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.4158\n",
      "Epoch 32/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3777\n",
      "Epoch 33/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train,epochs=33,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 831us/step - loss: 0.3302\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 169 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f76980504d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test_scaled[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "mse_test = model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8321879],\n",
       "       [2.5315142],\n",
       "       [3.0543156]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.942, 2.021, 3.423])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input(shape=X_train.shape[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30,activation='relu')(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden2 = keras.layers.Dense(30,activation='relu')(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.Concatenate()([inp,hidden2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(1)(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs=[inp], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 965us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "162/162 [==============================] - 0s 891us/step - loss: nan\n",
      "WARNING:tensorflow:6 out of the last 168 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7690249200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    " validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dynamic Models using Subclass APi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(keras.models.Model):\n",
    "    def __init__(self,units=30,activation='relu',**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units,activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    def call(self,inputs):\n",
    "        input_A,input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(input1)\n",
    "        concat =  keras.layers.concatenate([input_A,hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "model = WideAndDeep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 0.3612WARNING:tensorflow:From /home/robin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 26s - loss: 0.2965WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.1411s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3025 - val_loss: 0.3862\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3003 - val_loss: 0.4052\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.3013 - val_loss: 0.3825\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.2981 - val_loss: 0.3779\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.2980 - val_loss: 0.3842\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 837us/step - loss: 0.2974 - val_loss: 0.4161\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3047 - val_loss: 0.3762\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.2962 - val_loss: 0.3763\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.2949 - val_loss: 0.3860\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.2949 - val_loss: 0.3849\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.2937 - val_loss: 0.3860\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.2959 - val_loss: 0.3875\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.2923 - val_loss: 0.3859\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.2913 - val_loss: 0.3840\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.2927 - val_loss: 0.3875\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.2936 - val_loss: 0.3840\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.2909 - val_loss: 0.3766\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.2899 - val_loss: 0.3819\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.2926 - val_loss: 0.3857\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.2886 - val_loss: 0.4053\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3913\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.2876 - val_loss: 0.3830\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.2902 - val_loss: 0.3875\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.2867 - val_loss: 0.3778\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.2857 - val_loss: 0.3931\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.2861 - val_loss: 0.3726\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2856 - val_loss: 0.4086\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.2863 - val_loss: 0.3848\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.3743\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.2878 - val_loss: 0.3833\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train_scaled,y_train,epochs=30,validation_data=(X_valid_scaled,y_valid),callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 2048288703765432737202176.0000 - val_loss: 293879684487410876416.0000\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 66844211276316409856.0000 - val_loss: 3721205294986952704.0000\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 846405081854115840.0000 - val_loss: 47119351765008384.0000\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 823us/step - loss: 10717505697873920.0000 - val_loss: 596643703422976.0000\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 135709172170752.0000 - val_loss: 7554919301120.0000\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 808us/step - loss: 1718401236992.0000 - val_loss: 95663349760.0000\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 21759068160.0000 - val_loss: 1211324928.0000\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 803us/step - loss: 275521344.0000 - val_loss: 15338262.0000\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 3488752.7500 - val_loss: 194214.7656\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 44175.9297 - val_loss: 2460.7537\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 560.2997 - val_loss: 32.5407\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 8.3667 - val_loss: 1.9492\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4241 - val_loss: 1.5725\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3379 - val_loss: 1.5676\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.5675\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3368 - val_loss: 1.5676\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3371 - val_loss: 1.5675\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.5674\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3368 - val_loss: 1.5675\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5675\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5675\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.5676\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5675\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5675\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 1.3368 - val_loss: 1.5676\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5675\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.5674\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.5674\n",
      "162/162 [==============================] - 0s 685us/step - loss: 1.3505\n",
      "WARNING:tensorflow:8 out of the last 170 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f76545e9680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    " validation_data=(X_valid, y_valid),\n",
    " callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 636us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 750us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 768us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1861131601707008.0000 - val_loss: 176970317824.0000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 137964634112.0000 - val_loss: 104883625984.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 81766268928.0000 - val_loss: 62160445440.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 48459755520.0000 - val_loss: 36840112128.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 28720234496.0000 - val_loss: 21833711616.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 17021371392.0000 - val_loss: 12939993088.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10087903232.0000 - val_loss: 7669035008.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5978712576.0000 - val_loss: 4545144320.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3543355648.0000 - val_loss: 2693735168.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2100010112.0000 - val_loss: 1596470528.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1244593664.0000 - val_loss: 946166144.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 737622592.0000 - val_loss: 560756032.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 437160160.0000 - val_loss: 332338336.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 259087776.0000 - val_loss: 196964160.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 153551312.0000 - val_loss: 116733144.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 91003952.0000 - val_loss: 69183288.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 53934540.0000 - val_loss: 41002332.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 31964926.0000 - val_loss: 24300502.0000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 18944362.0000 - val_loss: 14401984.0000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11227585.0000 - val_loss: 8535506.0000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6654148.5000 - val_loss: 5058662.5000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3943650.0000 - val_loss: 2998083.5000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2337248.0000 - val_loss: 1776853.1250\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1385197.1250 - val_loss: 1053078.6250\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 820953.8125 - val_loss: 624123.5625\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 486547.7188 - val_loss: 369897.2188\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 288358.5938 - val_loss: 219226.8906\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 170899.7031 - val_loss: 129929.8906\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 101286.2422 - val_loss: 77006.3672\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 60028.9727 - val_loss: 45640.3125\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 35577.3438 - val_loss: 27050.6172\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 21085.8203 - val_loss: 16032.9814\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12497.2354 - val_loss: 9503.1152\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7407.1138 - val_loss: 5633.0151\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4390.4819 - val_loss: 3339.3669\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2602.6379 - val_loss: 1979.8782\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1543.0459 - val_loss: 1174.1328\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 915.0624 - val_loss: 696.5486\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 542.8763 - val_loss: 413.4577\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 322.2805 - val_loss: 245.6470\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 191.5350 - val_loss: 146.1678\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 114.0522 - val_loss: 87.2131\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 68.1397 - val_loss: 52.2603\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 40.9276 - val_loss: 31.5357\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 24.7970 - val_loss: 19.2434\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 15.2359 - val_loss: 11.9516\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9.5683 - val_loss: 7.6269\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.2106 - val_loss: 5.0619\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2216 - val_loss: 3.5402\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0429 - val_loss: 2.6363\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3442 - val_loss: 2.0994\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9297 - val_loss: 1.7794\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6837 - val_loss: 1.5887\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5378 - val_loss: 1.4751\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4513 - val_loss: 1.4072\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4003 - val_loss: 1.3671\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3701 - val_loss: 1.3429\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3521 - val_loss: 1.3282\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3415 - val_loss: 1.3195\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3353 - val_loss: 1.3141\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3314 - val_loss: 1.3108\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3292 - val_loss: 1.3088\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3280 - val_loss: 1.3076\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3272 - val_loss: 1.3068\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3267 - val_loss: 1.3063\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3265 - val_loss: 1.3060\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3263 - val_loss: 1.3058\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3262 - val_loss: 1.3056\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3262 - val_loss: 1.3055\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3055\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3054\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3054\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3054\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3053\n",
      "121/121 [==============================] - 0s 716us/step - loss: 1.3562\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 112733731160064.0000 - val_loss: 15604937728.0000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12165467136.0000 - val_loss: 9248442368.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7210007552.0000 - val_loss: 5481192960.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4273093120.0000 - val_loss: 3248495104.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2532499200.0000 - val_loss: 1925256704.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1500914816.0000 - val_loss: 1141025920.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 889534336.0000 - val_loss: 676241984.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 527192640.0000 - val_loss: 400782304.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 312446464.0000 - val_loss: 237528272.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 185175040.0000 - val_loss: 140773888.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 109746168.0000 - val_loss: 83431184.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 65042292.0000 - val_loss: 49446432.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 38548040.0000 - val_loss: 29304966.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22845956.0000 - val_loss: 17367934.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 13539923.0000 - val_loss: 10293296.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8024588.0000 - val_loss: 6100439.0000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4755868.0000 - val_loss: 3615493.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2818620.0000 - val_loss: 2142761.5000\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1670487.1250 - val_loss: 1269929.3750\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 990034.5000 - val_loss: 752637.3750\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 586755.7500 - val_loss: 446058.4375\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 347748.4375 - val_loss: 264361.7500\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 206097.9062 - val_loss: 156676.7500\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 122146.9766 - val_loss: 92856.3672\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 72392.4531 - val_loss: 55032.6055\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 42904.9531 - val_loss: 32615.9609\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 25428.6758 - val_loss: 19330.4258\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 15071.1025 - val_loss: 11456.6885\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8932.5674 - val_loss: 6790.2539\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5294.5322 - val_loss: 4024.7551\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3138.4297 - val_loss: 2385.7468\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1860.5682 - val_loss: 1414.3853\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1103.2300 - val_loss: 838.7191\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 654.3982 - val_loss: 497.5723\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 388.3885 - val_loss: 295.3872\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 230.7305 - val_loss: 175.5657\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 137.2874 - val_loss: 104.5487\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 81.9065 - val_loss: 62.4712\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 49.0914 - val_loss: 37.5469\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 29.6483 - val_loss: 22.7756\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 18.1225 - val_loss: 14.0226\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11.2905 - val_loss: 8.8350\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.2421 - val_loss: 5.7637\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8435 - val_loss: 3.9446\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4222 - val_loss: 2.8673\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5795 - val_loss: 2.2286\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0798 - val_loss: 1.8510\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7838 - val_loss: 1.6272\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6082 - val_loss: 1.4949\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5044 - val_loss: 1.4171\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4431 - val_loss: 1.3713\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4068 - val_loss: 1.3440\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3851 - val_loss: 1.3279\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3722 - val_loss: 1.3184\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3645 - val_loss: 1.3128\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3600 - val_loss: 1.3095\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3573 - val_loss: 1.3076\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3557 - val_loss: 1.3065\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3548 - val_loss: 1.3059\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3542 - val_loss: 1.3056\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3539 - val_loss: 1.3054\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3537 - val_loss: 1.3053\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3052\n",
      "121/121 [==============================] - 0s 698us/step - loss: 1.3036\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 121525260779520.0000 - val_loss: 17411897344.0000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13574160384.0000 - val_loss: 10319352832.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8044871680.0000 - val_loss: 6115878400.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4767882240.0000 - val_loss: 3624645632.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2825740288.0000 - val_loss: 2148186112.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1674706304.0000 - val_loss: 1273147264.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 992534528.0000 - val_loss: 754545344.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 588236864.0000 - val_loss: 447190176.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 348625280.0000 - val_loss: 265032272.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 206616800.0000 - val_loss: 157074624.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 122453768.0000 - val_loss: 93092000.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 72573576.0000 - val_loss: 55172060.0000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 43011512.0000 - val_loss: 32698352.0000\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 25491260.0000 - val_loss: 19379072.0000\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 15107711.0000 - val_loss: 11485249.0000\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8953757.0000 - val_loss: 6806880.5000\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5306548.5000 - val_loss: 4034183.0000\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3144985.7500 - val_loss: 2390911.2500\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1863912.6250 - val_loss: 1417005.8750\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1104668.8750 - val_loss: 839808.5000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 654695.1875 - val_loss: 497725.6250\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 388012.5312 - val_loss: 294984.9688\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 229960.5781 - val_loss: 174828.8281\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 136289.4062 - val_loss: 103616.1953\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 80773.9141 - val_loss: 61410.5586\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 47871.9609 - val_loss: 36396.9570\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 28372.4355 - val_loss: 21572.2852\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 16815.8105 - val_loss: 12786.0674\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9966.6572 - val_loss: 7578.7637\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5907.3970 - val_loss: 4492.4136\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3501.6174 - val_loss: 2663.2483\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2075.8376 - val_loss: 1579.1129\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1230.8068 - val_loss: 936.5262\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 729.9941 - val_loss: 555.6816\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 433.1898 - val_loss: 329.9453\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 257.2823 - val_loss: 196.1435\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 153.0216 - val_loss: 116.8096\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 91.2266 - val_loss: 69.7953\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 54.6085 - val_loss: 41.9247\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 32.9072 - val_loss: 25.3986\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 20.0425 - val_loss: 15.5967\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12.4189 - val_loss: 9.7876\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7.9024 - val_loss: 6.3411\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.2249 - val_loss: 4.2967\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6386 - val_loss: 3.0836\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6985 - val_loss: 2.3633\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1410 - val_loss: 1.9351\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8109 - val_loss: 1.6813\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6153 - val_loss: 1.5296\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4992 - val_loss: 1.4397\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4307 - val_loss: 1.3861\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3901 - val_loss: 1.3541\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3660 - val_loss: 1.3349\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3518 - val_loss: 1.3234\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3433 - val_loss: 1.3165\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3383 - val_loss: 1.3122\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3352 - val_loss: 1.3095\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3334 - val_loss: 1.3079\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3324 - val_loss: 1.3070\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3318 - val_loss: 1.3064\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3314 - val_loss: 1.3060\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3312 - val_loss: 1.3057\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3311 - val_loss: 1.3056\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3055\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3054\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3054\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3052\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3309 - val_loss: 1.3053\n",
      "121/121 [==============================] - 0s 709us/step - loss: 1.3486\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 862us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 726us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 824us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 985us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 676us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 671us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 624us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 623us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 987us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 605us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 595us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 609us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 50192899081502720.0000 - val_loss: 16034192949248.0000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7092745797632.0000 - val_loss: 2289687330816.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 1012844789760.0000 - val_loss: 326968115200.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 144634560512.0000 - val_loss: 46691045376.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 20653844480.0000 - val_loss: 6667501056.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 2949375232.0000 - val_loss: 952120896.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 421171392.0000 - val_loss: 135963232.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 60143320.0000 - val_loss: 19415632.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 8588481.0000 - val_loss: 2772580.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 1226433.0000 - val_loss: 395929.8438\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 175135.1094 - val_loss: 56544.8281\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 25011.5586 - val_loss: 8077.6548\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 3573.2856 - val_loss: 1155.2991\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 511.4589 - val_loss: 166.2937\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 74.1888 - val_loss: 24.9446\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 11.7287 - val_loss: 4.7044\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 2.8104 - val_loss: 1.7987\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 1.5384 - val_loss: 1.3801\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 1.3574 - val_loss: 1.3187\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 1.3310 - val_loss: 1.3077\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 1.3269 - val_loss: 1.3058\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 1.3263 - val_loss: 1.3055\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1.3262 - val_loss: 1.3052\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1.3261 - val_loss: 1.3053\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 1.3262 - val_loss: 1.3052\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 1.3262 - val_loss: 1.3052\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 1.3262 - val_loss: 1.3053\n",
      "121/121 [==============================] - 0s 590us/step - loss: 1.4985\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9314712470683648.0000 - val_loss: 3161009684480.0000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 1398275571712.0000 - val_loss: 451392405504.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 199673970688.0000 - val_loss: 64458964992.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 28513470464.0000 - val_loss: 9204745216.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 4071725312.0000 - val_loss: 1314439296.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 581443520.0000 - val_loss: 187702192.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 83030264.0000 - val_loss: 26803876.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 11856731.0000 - val_loss: 3827575.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 1693139.1250 - val_loss: 546574.8750\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 241782.6562 - val_loss: 78052.1328\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 34529.2852 - val_loss: 11147.2217\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 4932.2271 - val_loss: 1592.8232\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 705.5190 - val_loss: 228.5110\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 101.9226 - val_loss: 33.7008\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 15.6972 - val_loss: 5.9132\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 3.3987 - val_loss: 1.9596\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 1.6447 - val_loss: 1.3956\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 1.3945 - val_loss: 1.3174\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 1.3594 - val_loss: 1.3067\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 1.3543 - val_loss: 1.3052\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 1.3535 - val_loss: 1.3052\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 1.3536 - val_loss: 1.3052\n",
      "121/121 [==============================] - 0s 596us/step - loss: 1.3036\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9783055745024.0000 - val_loss: 3652835584.0000\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 1615835776.0000 - val_loss: 521625568.0000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 230741520.0000 - val_loss: 74488080.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 32949928.0000 - val_loss: 10636863.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 4705244.5000 - val_loss: 1518924.2500\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 671909.0000 - val_loss: 216900.1250\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 95950.5703 - val_loss: 30972.9316\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 13702.5986 - val_loss: 4422.9385\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 1957.7871 - val_loss: 632.4625\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 280.7076 - val_loss: 91.2913\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 41.2060 - val_loss: 14.1097\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 7.0268 - val_loss: 3.1220\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 2.1444 - val_loss: 1.5583\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 1.4477 - val_loss: 1.3399\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 1.3480 - val_loss: 1.3095\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 1.3337 - val_loss: 1.3057\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 1.3315 - val_loss: 1.3052\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 1.3311 - val_loss: 1.3052\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 1.3310 - val_loss: 1.3052\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3052\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 1.3310 - val_loss: 1.3053\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 1.3310 - val_loss: 1.3053\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 1.3310 - val_loss: 1.3054\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 1.3311 - val_loss: 1.3052\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3053\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 1.3310 - val_loss: 1.3053\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1.3310 - val_loss: 1.3053\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3052\n",
      "121/121 [==============================] - 0s 586us/step - loss: 1.3486\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 587us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 620us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 996us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 762us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 648us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 618us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 609us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 583us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 587us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 586us/step - loss: nan\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7654540dd0>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-a02da166f8b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[1;32m     11\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f7654540dd0>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "param_distribs = {\n",
    " \"n_hidden\": [0, 1, 2, 3],\n",
    " \"n_neurons\": np.arange(1, 100),\n",
    " \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    " validation_data=(X_valid, y_valid),\n",
    " callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005401338287266035, 'n_hidden': 1, 'n_neurons': 23}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3361186583836873"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(23,activation='relu',input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.7601 - val_loss: 1.0500\n",
      "Epoch 2/33\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.8072 - val_loss: 0.7188\n",
      "Epoch 3/33\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.6359 - val_loss: 0.6205\n",
      "Epoch 4/33\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.5438 - val_loss: 0.5486\n",
      "Epoch 5/33\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4860 - val_loss: 0.5067\n",
      "Epoch 6/33\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.4537 - val_loss: 0.4861\n",
      "Epoch 7/33\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.4343 - val_loss: 0.4752\n",
      "Epoch 8/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4666\n",
      "Epoch 9/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4599\n",
      "Epoch 10/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.4537\n",
      "Epoch 11/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.4506\n",
      "Epoch 12/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4434\n",
      "Epoch 13/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4436\n",
      "Epoch 14/33\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3903 - val_loss: 0.4390\n",
      "Epoch 15/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4346\n",
      "Epoch 16/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4358\n",
      "Epoch 17/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.4396\n",
      "Epoch 18/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.4341\n",
      "Epoch 19/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.4290\n",
      "Epoch 20/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4265\n",
      "Epoch 21/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.4249\n",
      "Epoch 22/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4244\n",
      "Epoch 23/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.4173\n",
      "Epoch 24/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.4266\n",
      "Epoch 25/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.4190\n",
      "Epoch 26/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.4222\n",
      "Epoch 27/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.4185\n",
      "Epoch 28/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.4194\n",
      "Epoch 29/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.4161\n",
      "Epoch 30/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.4215\n",
      "Epoch 31/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.4136\n",
      "Epoch 32/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3551 - val_loss: 0.4161\n",
      "Epoch 33/33\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.4131\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.000540138)\n",
    "model.compile(loss='mean_squared_error',optimizer=opt)\n",
    "history = model.fit(X_train_scaled,y_train,epochs=33,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 797us/step - loss: 0.3698\n",
      "WARNING:tensorflow:9 out of the last 171 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f76a01d4a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled,y_test)\n",
    "X_new = X_test_scaled[:3]\n",
    "y_pred = model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82697237],\n",
       "       [2.513434  ],\n",
       "       [3.142375  ]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.942, 2.021, 3.423])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
